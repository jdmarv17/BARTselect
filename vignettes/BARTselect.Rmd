---
title: "BARTselect"
output: rmarkdown::html_vignette
bibliography: REFERENCES.bib
vignette: >
  %\VignetteIndexEntry{BARTselect}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


## Introduction

This vignette provides an overview of how to use $\tt{BARTselect}$, which provides tools for interaction and variable selection using Bayesian Additive Regression Trees (BART). $\tt{BARTselect}$ takes advantage of the R package $\tt{dbarts}$ for fast computation of BART models (@chipman2010bart). Variable selection is accomplished using an adaption of the method proposed in @bleich2014variable. Interaction selection is done using the method described in __________.


Important parameters to consider include the quantiles used for variable and interactions selection, the prior power for the BART models, and the number of null runs to generate thresholds. Since there are not default specifications that will work well for all selection scenarios, users may need to run $\tt{BARTselect()}$ with different parameter values to return more or less stringent selection. 


Users who wish for more stringent selection for a given threshold should decrease the $\alpha$ value associated with that threshold's quantile. For example, if $\tt{BARTselect()}$ with default parameters selects too many interactions, the user may decrease the alpha_g parameter to make the global CIP threshold more stringent. The threshold for CMDs is controlled by setting set_diff_thresh = FALSE and specifying alpha_d, or by setting set_diff_thresh = TRUE and providing a diff_thresh value. Since CMDs in the null runs are a mix of positive and negative, thresholds generated from these values can be unpredictable. We find that using multiples of alpha_d = $2 / p(p-1)$ is a suitable starting place for automatic threshold generation that is adaptive to the data's dimensionality. Users can also specify the quantile without making it data-dependent. If users desire even more control over the CMD threshold they can set set_diff_thresh = TRUE and specify a range of threshold to test (for instance seq(0, 0.2, by = 0.025)). The prior_base parameter can also be adjusted to impact the prior probability of small or large trees but we find it easier to adjust only the prior_power.


The prior power for the BART models plays an important role in determining the size of posterior trees. Higher values of this parameter will induce smaller trees while smaller values will induce larger trees. Considering that interaction selections are based on tree co-inclusion, this parameter can play a large role in high dimensional settings. The prior power also plays a role on threshold generation. For this reason, we recommend setting the prior power before tuning parameters related to threshold generation. Datasets with fewer covariates $p \approx 10$ tend to have decent performance with the prior_power parameter set between 1 and 4. Datasets with many covariates $p \approx 100$ tend to need a higher prior_power value (4-6) to stop the trees from growing too large. Very high dimensional datasets $p > 1000$ tend to require very high prior_power values (6-8).


The parameter num_null_run determines how many times BART will be fit to the permuted outcome vector to obtain null CIPs, MIPs, and CMDs. While increasing this parameter will theoretically improve threshold estimation, due to computational constraints users may wish to keep this value relatively low. BART will be run num_null_run + 1 times which may take a long time depending on available computing resources. We find that acceptable performance can be achieved with num_null_run between 5 and 10 but recommend larger values if computing resources allow (>20).

<br>

## Installation

You can install the package from GitHub:

```{r installation}
#devtools::install_github("jdmarv17/BARTselect")
library(bart.package.test)
```


## Example: Newborn Birth Weights

We will illustrate BARTselect using a dataset of newborn birth weights from the $\tt{MASS}$ package. This dataset contains an outcome variable (newborn birth weight) and covariates related to the mother and her care. First, we will load the data and then remove a binarized version of the birth weight variable.

### Load libraries and data:

```{r libraries, message=FALSE, warning=FALSE}
library(dbarts)
library(MASS)
library(dplyr)
```

```{r data}
birth_weights = 
  MASS::birthwt %>%
  dplyr::mutate(race = factor(race, levels = c(1, 2, 3))) %>%
  dplyr::select(., -low)

head(birth_weights)
```

<br>

Using the covariates in the dataset we wish to find variables and interactions that are predictive of the newborn birth weight. To do this we just need to run the $\tt{BARTselect()}$ which will do automatic variable and interaction selection. We use a prior_power = 1 due to the low number of covariates. We set the CIP threshold alpha_g = 0.05 and the variable selection threshold alpha_g_vip = 0.05. We also use the data-dependent quantile for the CMD threshold of alpha_d = $2 / p(p-1)$. Finally, we set the null runs with num_null_run = 15. 


We recommend using at least 4 chains if possible. The parameter num_threads_bart determines the number of threads passed to $\tt{dbarts::bart2()}$ and is not recommended to be larger than the number of chains. Finally, num_threads_wrangle determines the number of threads used for wrangling of the posterior results. This parameter can be set independently of the other thread arguments. Increasing the number of threads used for wrangling will speed up the processing $\tt{BARTselect()}$ does after running $\tt{dbarts::bart2()}$.


### Run BARTselect:

```{r BARTselect}
p = ncol(birth_weights) - 1
alpha_d =  (8 / (p * (p - 1)))
chains = 4
bart_threads = 4
wrangle_threads = 8

selections = BARTselect(bwt ~ ., data = birth_weights,
                        num_trees = 10, num_samps = 10000, num_burn = 5000,
                        num_chains = chains, num_thin = 5, num_null_run = 10,
                        num_threads_bart = bart_threads, num_threads_wrangle = wrangle_threads,
                        alpha_g = 0.1, alpha_g_vip = 0.1,
                        alpha_d = alpha_d, set_diff_thresh = FALSE,
                        prior_power = 1, prior_base = 0.95, method = "global",
                        response_type = "continuous", hierarchical = TRUE)
```


While we can set a seed that will give us the same permuted outcomes for the null runs, each run of BART across multiple chains makes it challenging to reproduce exact results for a model with randomness in its fit process. Results for this dataset tend to be stable and selections should be stable even if exact thresholds are not matched. 

### Print selections:

```{r}
# selected interactions:
selections[[12]]
# selected variables:
selections[[11]]
```


### Fit model using selections:

Since $\tt{BARTselect()}$ selected an interaction between levels of the race variable and the smoke variable we have evidence that the interaction between race and smoke is predictive of newborn birth weight. We will include an interaction using all levels of the race variable in the final interpretable model.

```{r}
mod = lm(bwt ~ lwt + race*smoke, data = birth_weights)
summary(mod)
```


### More complex cases:

Depending on the data at hand, the selections from $\tt{BARTselect()}$ may not be very stable. By this, we mean that repeatedly running $\tt{BARTselect()}$ on the same data may produce different selections. This is due to several interacting factors like the co-linearity in the data, the ratio of signal to noise variables, and the chosen $\tt{BARTselect()}$ parameters. If the user experiences such instability they are recommended to run $\tt{BARTselect()}$ a number of times (10-20) and select the variables or interactions chosen most often to be predictive of the outcome.


